{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from importlib import reload\n",
    "from helper_funcs import *\n",
    "from make_models2 import *\n",
    "\n",
    "# Make tqdm work for notebooks\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "tqdm = partial(tqdm, position=0, leave=True)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "indir = '/mmfs1/data/liacz/Documents/Bilingualism_CVAE/data/array_brains'\n",
    "BRAIN_data = np.load(os.path.join(indir, \"arr_combine/BRAIN_data.npy\"))\n",
    "DX_subs = np.load(os.path.join(indir, \"arr_combine/DX_subs.npy\"))\n",
    "TD_subs = np.load(os.path.join(indir, \"arr_combine/TD_subs.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #BRAIN_data = np.array(BRAIN_data)\n",
    "# nsubs = BRAIN_data.shape[0]\n",
    "# print([arr.shape for arr in [BRAIN_ds, BRAIN_subs, BRAIN_data]])\n",
    "# print(nsubs)\n",
    "# print((BRAIN_data.min(),BRAIN_data.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/mmfs1/data/liacz/Documents/Bilingualism_CVAE/data/legend.csv')\n",
    "# BI_subs = df.loc[df['bilingualism'].values == 1.0, 'ds_par_id']\n",
    "# MO_subs = df.loc[df['bilingualism'].values == 0.0, 'ds_par_id']\n",
    "# BRAIN_ds_subs = [BRAIN_ds[i]+'_'+BRAIN_subs[i] for i in range(0,len(BRAIN_subs))]\n",
    "# BI_subs = [sub in BI_subs.to_list() for sub in BRAIN_ds_subs]\n",
    "# MO_subs = [sub in MO_subs.to_list() for sub in BRAIN_ds_subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BI_subs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e540a68d3d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBI_subs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMO_subs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BI_subs' is not defined"
     ]
    }
   ],
   "source": [
    "# print(BI_subs.count(True))\n",
    "# print(MO_subs.count(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TD_subs = BRAIN_data[MO_subs,:,:,:] # Data of Monolinguals \n",
    "# DX_subs = BRAIN_data[BI_subs,:,:,:] # Data of Bilinguals\n",
    "print(TD_subs.shape)\n",
    "print(DX_subs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vae = False\n",
    "if train_vae:\n",
    "    \n",
    "    latent_dim = 32\n",
    "    batch_size = 16\n",
    "    disentangle = False\n",
    "    gamma = 100\n",
    "\n",
    "    encoder, decoder, vae = get_MRI_VAE_3D(input_shape=(64,64,64,1), \n",
    "                                            latent_dim=32, \n",
    "                                            batch_size = batch_size, \n",
    "                                            disentangle=True,\n",
    "                                            gamma=gamma,\n",
    "                                            kernel_size = 3,\n",
    "                                            filters = 48,\n",
    "                                            intermediate_dim = 128,\n",
    "                                            nlayers = 2,\n",
    "                                            bias=True)\n",
    "\n",
    "\n",
    "    loss = list()\n",
    "    fn = '/mmfs1/data/liacz/Documents/Bilingualism_CVAE/data/tf_outputs/VAE/VAE_weights'\n",
    "        \n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatches = 5000\n",
    "if train_vae:\n",
    "    for i in tqdm(range(1,nbatches)):    \n",
    "        \n",
    "        batch_idx = np.random.randint(low=0,high=BRAIN_data.shape[0],size=batch_size)\n",
    "        data_batch = BRAIN_data[batch_idx,:,:,:]\n",
    "        \n",
    "        history = vae.train_on_batch(data_batch);\n",
    "        mse = ((data_batch-vae.predict(data_batch)[:,:,:,:,0])**2).mean()\n",
    "        loss.append(history);\n",
    "        \n",
    "        if np.mod(i,5)==0: # Plot training progress\n",
    "            im1 = data_batch[0,32,:,:];\n",
    "            im = vae.predict(data_batch)[0,32,:,:,0];\n",
    "            plot_trainProgress(loss,im,im1);\n",
    "\n",
    "        if np.mod(i,10)==0: # Save every 10 batches\n",
    "            pickle.dump(loss,open(fn+'_loss.pickle','wb'))\n",
    "            print(i)\n",
    "            vae.save_weights(fn)    \n",
    "        \n",
    "        if mse < .0001:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cvae = True\n",
    "if train_cvae:\n",
    "    \n",
    "    latent_dim = 16\n",
    "    batch_size = 16\n",
    "    beta = 1;gamma = 100\n",
    "    disentangle = True\n",
    "    cvae, z_encoder, s_encoder, cvae_decoder = get_MRI_CVAE_3D(latent_dim=latent_dim,beta=beta, disentangle=disentangle, gamma=gamma, bias=True, batch_size = batch_size)\n",
    "    loss = list()    \n",
    "    \n",
    "    fdir = '/mmfs1/data/liacz/Documents/Bilingualism_CVAE/data/tf_outputs/CVAE/'\n",
    "    fn = 'CVAE_weights'\n",
    "    \n",
    "    fn = os.path.join(fdir,fn)\n",
    "    loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_encoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvae_decoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_batch = DX_subs[np.random.randint(low=0,high=DX_subs.shape[0],size=batch_size),:,:,:];\n",
    "TD_batch = TD_subs[np.random.randint(low=0,high=TD_subs.shape[0],size=batch_size),:,:,:];\n",
    "\n",
    "if len(loss)==0:\n",
    "    loss.append(np.nan)\n",
    "    im,im1,ss = cvae_query(BRAIN_data,s_encoder,z_encoder,cvae_decoder);\n",
    "    plot_trainProgress(loss,im,im1);\n",
    "    loss = list()\n",
    "else:\n",
    "    im,im1,ss = cvae_query(BRAIN_data,s_encoder,z_encoder,cvae_decoder);\n",
    "    plot_trainProgress(loss,im,im1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatches = 5000\n",
    "if train_cvae:\n",
    "    for i in tqdm(range(1,nbatches)):\n",
    "        \n",
    "        DX_batch = DX_subs[np.random.randint(low=0,high=DX_subs.shape[0],size=batch_size),:,:,:];\n",
    "        TD_batch = TD_subs[np.random.randint(low=0,high=TD_subs.shape[0],size=batch_size),:,:,:];\n",
    "        \n",
    "        hist = cvae.train_on_batch([DX_batch,TD_batch]);\n",
    "        loss.append(hist);\n",
    "        \n",
    "        mse = ((np.array([DX_batch,TD_batch])-np.array(cvae.predict([DX_batch,TD_batch]))[:,:,:,:,:,0])**2).mean()\n",
    "\n",
    "        assert not np.isnan(hist),'loss is NaN - somethings wrong'\n",
    "\n",
    "        im,im1,ss = cvae_query(BRAIN_data, s_encoder, z_encoder, cvae_decoder); \n",
    "\n",
    "        \n",
    "\n",
    "        if np.mod(i,5)==0: # Plot training progress\n",
    "            plot_trainProgress(loss,im,im1);\n",
    "            pickle.dump(loss,open(fn+'_loss.pickle','wb'))\n",
    "            plot_four(DX_batch, TD_batch, z_encoder, s_encoder,cvae_decoder,cvae,idx=0)\n",
    "            plot_four(DX_batch, TD_batch, z_encoder, s_encoder,cvae_decoder,cvae,idx=1)\n",
    "\n",
    "        if np.mod(i,10)==0: # Save every 10 batches\n",
    "            cvae.save_weights(fn)\n",
    "            \n",
    "        if mse < .0001:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
