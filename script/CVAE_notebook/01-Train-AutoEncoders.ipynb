{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='debug.log', level=logging.DEBUG)\n",
    "\n",
    "# Then in your code...\n",
    "def some_function():\n",
    "    logging.info('Starting function...')\n",
    "    # ...code...\n",
    "    logging.info('Finished function.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 13:53:26.332440: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-23 13:53:26.358117: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-23 13:53:26.401401: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-23 13:53:26.424102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755971606.449113 1891241 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755971606.454155 1891241 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755971606.486346 1891241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755971606.486369 1891241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755971606.486371 1891241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755971606.486372 1891241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-23 13:53:26.490734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 13:53:31.709889: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import sys\n",
    "import os\n",
    "os.chdir('/projects/sccn/weili_A1/liacz/Documents/Bilingualism_CVAE')\n",
    "#set up path to import helper_funcs\n",
    "sys.path.append('/projects/sccn/weili_A1/liacz/Documents/Bilingualism_CVAE/misc')\n",
    "from helper_funcs import *\n",
    "from make_models2 import *\n",
    "\n",
    "# Make tqdm work for notebooks\n",
    "from functools import partial #already installed in conda environment\n",
    "from tqdm import tqdm\n",
    "tqdm = partial(tqdm, position=0, leave=True)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "# from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "BRAIN_data = np.load(\"data/array_brains/arr_combine/oct24/BRAIN_data.npy\")\n",
    "DX_subs = np.load(\"data/array_brains/arr_combine/oct24/DX_subs.npy\")\n",
    "TD_subs = np.load(\"data/array_brains/arr_combine/oct24/TD_subs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #BRAIN_data = np.array(BRAIN_data)\n",
    "# nsubs = BRAIN_data.shape[0]\n",
    "# print([arr.shape for arr in [BRAIN_ds, BRAIN_subs, BRAIN_data]])\n",
    "# print(nsubs)\n",
    "# print((BRAIN_data.min(),BRAIN_data.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/mmfs1/data/liacz/Documents/Bilingualism_CVAE/data/legend.csv')\n",
    "# BI_subs = df.loc[df['bilingualism'].values == 1.0, 'ds_par_id']\n",
    "# MO_subs = df.loc[df['bilingualism'].values == 0.0, 'ds_par_id']\n",
    "# BRAIN_ds_subs = [BRAIN_ds[i]+'_'+BRAIN_subs[i] for i in range(0,len(BRAIN_subs))]\n",
    "# BI_subs = [sub in BI_subs.to_list() for sub in BRAIN_ds_subs]\n",
    "# MO_subs = [sub in MO_subs.to_list() for sub in BRAIN_ds_subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(BI_subs.count(True))\n",
    "# print(MO_subs.count(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1644, 64, 64, 64)\n",
      "(853, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# TD_subs = BRAIN_data[MO_subs,:,:,:] # Data of Monolinguals \n",
    "# DX_subs = BRAIN_data[BI_subs,:,:,:] # Data of Bilinguals\n",
    "print(TD_subs.shape)\n",
    "print(DX_subs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 18 20:43:12 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off |   00000000:17:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             45W /  300W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off |   00000000:65:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             43W /  300W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off |   00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   30C    P0             43W /  300W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off |   00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             43W /  300W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv3D, Conv3DTranspose, Flatten, Dense, Reshape, Lambda\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# 1) The reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch   = K.shape(z_mean)[0]\n",
    "    dim     = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "# 2) Build encoder + decoder (no add_loss, no Functional‐API VAE)\n",
    "def build_encoder_decoder(input_shape, latent_dim,\n",
    "                          nlayers=2, base_filters=32,\n",
    "                          kernel_size=3, intermediate_dim=128,\n",
    "                          use_bias=True):\n",
    "    # -- Encoder\n",
    "    inputs = Input(shape=input_shape, name=\"encoder_input\")\n",
    "    x = inputs\n",
    "    filters = base_filters\n",
    "    for _ in range(nlayers):\n",
    "        filters *= 2\n",
    "        x = Conv3D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=2,\n",
    "                   padding=\"same\",\n",
    "                   activation=\"relu\",\n",
    "                   use_bias=use_bias)(x)\n",
    "    shape_info = K.int_shape(x)  # needed for decoder reshape\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(intermediate_dim, activation=\"relu\", use_bias=use_bias)(x)\n",
    "    z_mean    = Dense(latent_dim, name=\"z_mean\", use_bias=use_bias)(x)\n",
    "    z_log_var = Dense(latent_dim, name=\"z_log_var\", use_bias=use_bias)(x)\n",
    "    z         = Lambda(sampling, name=\"z\")([z_mean, z_log_var])\n",
    "\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    # -- Decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name=\"z_sampling\")\n",
    "    x = Dense(intermediate_dim, activation=\"relu\", use_bias=use_bias)(latent_inputs)\n",
    "    total_dims = shape_info[1] * shape_info[2] * shape_info[3] * shape_info[4]\n",
    "    x = Dense(total_dims, activation=\"relu\", use_bias=use_bias)(x)\n",
    "    x = Reshape((shape_info[1],\n",
    "                 shape_info[2],\n",
    "                 shape_info[3],\n",
    "                 shape_info[4]))(x)\n",
    "\n",
    "    filters = shape_info[4]\n",
    "    for _ in range(nlayers):\n",
    "        x = Conv3DTranspose(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=2,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            use_bias=use_bias)(x)\n",
    "        filters //= 2\n",
    "\n",
    "    outputs = Conv3DTranspose(filters=input_shape[3],\n",
    "                              kernel_size=kernel_size,\n",
    "                              padding=\"same\",\n",
    "                              activation=\"sigmoid\",\n",
    "                              name=\"decoder_output\",\n",
    "                              use_bias=use_bias)(x)\n",
    "\n",
    "    decoder = Model(latent_inputs, outputs, name=\"decoder\")\n",
    "    return encoder, decoder\n",
    "\n",
    "\n",
    "# 3) Optional disentanglement helper\n",
    "def compute_tc_and_disc(z, gamma):\n",
    "    # batch‐split\n",
    "    z_top, z_bottom = tf.split(z, 2, axis=0)\n",
    "    # latent‐split\n",
    "    z1_a, z1_b = tf.split(z_top,    2, axis=1)\n",
    "    z2_a, z2_b = tf.split(z_bottom, 2, axis=1)\n",
    "\n",
    "    # build positive / negative pairs\n",
    "    q     = tf.concat([tf.concat([z1_b, z1_b], axis=1),\n",
    "                       tf.concat([z2_b, z2_b], axis=1)],\n",
    "                      axis=0)\n",
    "    q_bar = tf.concat([tf.concat([z1_b, z2_b], axis=1),\n",
    "                       tf.concat([z2_b, z1_b], axis=1)],\n",
    "                      axis=0)\n",
    "\n",
    "    discriminator = tf.keras.Sequential([\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ], name=\"discriminator\")\n",
    "\n",
    "    eps = 1e-7\n",
    "    q_score_raw     = discriminator(q)\n",
    "    q_bar_score_raw = discriminator(q_bar)\n",
    "\n",
    "    q_score     = tf.clip_by_value((q_score_raw     + 0.1) * 0.85, eps, 1-eps)\n",
    "    q_bar_score = tf.clip_by_value((q_bar_score_raw + 0.1) * 0.85, eps, 1-eps)\n",
    "\n",
    "    # total-correlation term\n",
    "    tc_loss = tf.reduce_mean(tf.math.log(q_score / (1 - q_score)))\n",
    "    # discriminator cross‐entropy term\n",
    "    disc_loss = tf.reduce_mean(-tf.math.log(q_score)\n",
    "                               - tf.math.log(1 - q_bar_score))\n",
    "\n",
    "    return gamma * tc_loss, disc_loss\n",
    "\n",
    "\n",
    "# 4) The subclassed VAE\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 image_size,\n",
    "                 channels,\n",
    "                 gamma=1.0,\n",
    "                 disentangle=False,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.image_size = image_size\n",
    "        self.channels   = channels\n",
    "        self.gamma      = gamma\n",
    "        self.disentangle = disentangle\n",
    "\n",
    "        # Trackers\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.recon_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker    = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "        if disentangle:\n",
    "            self.tc_loss_tracker   = tf.keras.metrics.Mean(name=\"tc_loss\")\n",
    "            self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        m = [self.total_loss_tracker,\n",
    "             self.recon_loss_tracker,\n",
    "             self.kl_loss_tracker]\n",
    "        if self.disentangle:\n",
    "            m += [self.tc_loss_tracker, self.disc_loss_tracker]\n",
    "        return m\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x = tf.cast(data, tf.float32) # expecting shape (batch, X,Y,Z,channels)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 1) encode\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            # 2) decode\n",
    "            x_recon = self.decoder(z)\n",
    "\n",
    "            # 3) reconstruction loss (MSE × volume)\n",
    "            vol_size = (self.image_size ** 3) * self.channels\n",
    "            recon_loss = tf.reduce_mean(tf.square(x - x_recon)) * vol_size\n",
    "\n",
    "            # 4) KL divergence\n",
    "            kl = -0.5 * (1 + z_log_var\n",
    "                         - tf.square(z_mean)\n",
    "                         - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl, axis=1))\n",
    "\n",
    "            total_loss = recon_loss + kl_loss\n",
    "\n",
    "            # 5) (optional) disentanglement\n",
    "            if self.disentangle:\n",
    "                tc, disc = compute_tc_and_disc(z, gamma=self.gamma)\n",
    "                total_loss += tc + disc\n",
    "\n",
    "        # 6) backprop\n",
    "        grads = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        # 7) update trackers\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.recon_loss_tracker.update_state(recon_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        if self.disentangle:\n",
    "            self.tc_loss_tracker.update_state(tc)\n",
    "            self.disc_loss_tracker.update_state(disc)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_vae:\n",
    "    \n",
    "    latent_dim = 32\n",
    "    batch_size = 16\n",
    "    disentangle = False\n",
    "    gamma = 100\n",
    "\n",
    "    encoder, decoder, vae = get_MRI_VAE_3D(input_shape=(64,64,64,1), \n",
    "                                            latent_dim=32, \n",
    "                                            batch_size = batch_size, \n",
    "                                            disentangle=True,\n",
    "                                            gamma=gamma,\n",
    "                                            kernel_size = 3,\n",
    "                                            filters = 48,\n",
    "                                            intermediate_dim = 128,\n",
    "                                            nlayers = 2,\n",
    "                                            bias=True)\n",
    "\n",
    "\n",
    "    loss = list()\n",
    "    fn = '/mmfs1/data/liacz/Documents/Bilingualism_CVAE/data/tf_outputs/VAE/VAE_weights'\n",
    "        \n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64, 64, 64, 1)\n",
    "latent_dim  = 32\n",
    "\n",
    "encoder, decoder = build_encoder_decoder(\n",
    "    input_shape=input_shape,\n",
    "    latent_dim=latent_dim,\n",
    "    nlayers=2,\n",
    "    base_filters=32,\n",
    "    intermediate_dim=128\n",
    ")\n",
    "\n",
    "# b) instantiate the subclassed VAE\n",
    "vae = VAE(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    image_size=input_shape[0],\n",
    "    channels=input_shape[3],\n",
    "    gamma=100.0,\n",
    "    disentangle=True,\n",
    "    name=\"mri_vae_3d\"\n",
    ")\n",
    "\n",
    "# c) compile & train\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "# assume `train_dataset` yields batches of shape (batch,64,64,64,1)\n",
    "# vae.fit(train_dataset, epochs=50, batch_size=32)\n",
    "\n",
    "fn = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape            </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to            </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv3d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv3d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │ conv3d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">524288</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">67,108,992</span> │ flatten_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                             │                         │                │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv3d_20 (\u001b[38;5;33mConv3D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m1,792\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv3d_21 (\u001b[38;5;33mConv3D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m221,312\u001b[0m │ conv3d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m524288\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ conv3d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │     \u001b[38;5;34m67,108,992\u001b[0m │ flatten_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z_mean (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │          \u001b[38;5;34m4,128\u001b[0m │ dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z_log_var (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │          \u001b[38;5;34m4,128\u001b[0m │ dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z (\u001b[38;5;33mLambda\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                             │                         │                │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,340,352</span> (256.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,340,352\u001b[0m (256.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,340,352</span> (256.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,340,352\u001b[0m (256.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                               </span>┃<span style=\"font-weight: bold\"> Output Shape                    </span>┃<span style=\"font-weight: bold\">           Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ z_sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">524288</span>)                  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,633,152</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ reshape_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ conv3d_transpose_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3DTranspose</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ conv3d_transpose_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3DTranspose</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">221,248</span> │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ decoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3DTranspose</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,729</span> │\n",
       "└────────────────────────────────────────────┴─────────────────────────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ z_sampling (\u001b[38;5;33mInputLayer\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      │                 \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     │             \u001b[38;5;34m4,224\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m524288\u001b[0m)                  │        \u001b[38;5;34m67,633,152\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ reshape_10 (\u001b[38;5;33mReshape\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │                 \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ conv3d_transpose_20 (\u001b[38;5;33mConv3DTranspose\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m442,496\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ conv3d_transpose_21 (\u001b[38;5;33mConv3DTranspose\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m221,248\u001b[0m │\n",
       "├────────────────────────────────────────────┼─────────────────────────────────┼───────────────────┤\n",
       "│ decoder_output (\u001b[38;5;33mConv3DTranspose\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │             \u001b[38;5;34m1,729\u001b[0m │\n",
       "└────────────────────────────────────────────┴─────────────────────────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,302,849</span> (260.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,302,849\u001b[0m (260.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,302,849</span> (260.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,302,849\u001b[0m (260.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m BRAIN_data[idx]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 3) Train on batch, unpack history\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m total_loss, recon_loss, kl_loss \u001b[38;5;241m=\u001b[39m h[:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     20\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(total_loss)\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:605\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata\u001b[39m():\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[0;32m--> 605\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:228\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[1;32m    227\u001b[0m     ):\n\u001b[0;32m--> 228\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:114\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    116\u001b[0m         outputs,\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    118\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[0;32mIn[35], line 148\u001b[0m, in \u001b[0;36mVAE.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m--> 148\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# expecting shape (batch, X,Y,Z,channels)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;66;03m# 1) encode\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         z_mean, z_log_var, z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "losses = []\n",
    "nbatches = 100\n",
    "batch_size = 32\n",
    "\n",
    "# 1) Make sure data has channel dim\n",
    "BRAIN_data = BRAIN_data[..., np.newaxis]\n",
    "\n",
    "for i in tqdm(range(nbatches)):\n",
    "    # 2) Sample a random batch\n",
    "    idx = np.random.randint(0, BRAIN_data.shape[0], size=batch_size)\n",
    "    x_batch = BRAIN_data[idx]\n",
    "\n",
    "    # 3) Train on batch, unpack history\n",
    "    h = vae.train_on_batch(x_batch)\n",
    "    total_loss, recon_loss, kl_loss = h[:3]\n",
    "    losses.append(total_loss)\n",
    "\n",
    "    # 4) Compute a quick MSE on the first example\n",
    "    x_rec = vae.predict(x_batch[:1])\n",
    "    mse = np.mean((x_batch[0] - x_rec[0])**2)\n",
    "\n",
    "    # 5) Every 5 iterations, visualize one slice\n",
    "    if i % 5 == 0:\n",
    "        slice_idx = x_batch.shape[1] // 2\n",
    "        im_gt = x_batch[0, slice_idx, ..., 0]\n",
    "        im_rec = x_rec[0, slice_idx, ..., 0]\n",
    "        plot_trainProgress(losses, im_rec, im_gt)\n",
    "\n",
    "    # 6) Every 10 iterations, checkpoint\n",
    "    if i % 10 == 0:\n",
    "        pickle.dump(losses, open(fn + '_loss.pickle','wb'))\n",
    "        vae.save_weights(fn)\n",
    "\n",
    "    # 7) Early stop on MSE\n",
    "    if mse < 5e-4:\n",
    "        print(f\"Stopping early at batch {i}, mse={mse:.6f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cvae = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m;gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      6\u001b[0m disentangle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m cvae, z_encoder, s_encoder, cvae_decoder \u001b[38;5;241m=\u001b[39m \u001b[43mget_MRI_CVAE_3D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisentangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisentangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()    \n\u001b[1;32m     10\u001b[0m fdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_outputs/CVAE/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/projects/sccn/weili_A1/liacz/Documents/Bilingualism_CVAE/misc/make_models2.py:313\u001b[0m, in \u001b[0;36mget_MRI_CVAE_3D\u001b[0;34m(input_shape, latent_dim, beta, disentangle, gamma, bias, batch_size)\u001b[0m\n\u001b[1;32m    311\u001b[0m     q_bar_score \u001b[38;5;241m=\u001b[39m (discriminator(q_bar)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m.1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m.85\u001b[39m \u001b[38;5;66;03m# +.1 * .85 so that it's 0<x<1\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     q_score \u001b[38;5;241m=\u001b[39m (discriminator(q)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m.1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m.85\u001b[39m \n\u001b[0;32m--> 313\u001b[0m     tc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mq_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    314\u001b[0m     discriminator_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m K\u001b[38;5;241m.\u001b[39mlog(q_score) \u001b[38;5;241m-\u001b[39m K\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m q_bar_score)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/keras/src/legacy/backend.py:997\u001b[0m, in \u001b[0;36mlog\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras._legacy.backend.log\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlog\u001b[39m(x):\n\u001b[1;32m    996\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"DEPRECATED.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 997\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:5689\u001b[0m, in \u001b[0;36mlog\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   5687\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   5688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m-> 5689\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[1;32m   5692\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:5730\u001b[0m, in \u001b[0;36mlog_eager_fallback\u001b[0;34m(x, name, ctx)\u001b[0m\n\u001b[1;32m   5729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlog_eager_fallback\u001b[39m(x: Annotated[Any, TV_Log_T], name, ctx) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Annotated[Any, TV_Log_T]:\n\u001b[0;32m-> 5730\u001b[0m   _attr_T, (x,) \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_to_matching_eager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplex64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplex128\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5731\u001b[0m   _inputs_flat \u001b[38;5;241m=\u001b[39m [x]\n\u001b[1;32m   5732\u001b[0m   _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T)\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:251\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# First see if we can get a valid dtype with the default conversion\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# and see if it matches an allowed dtypes. Some ops like ConcatV2 may\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# not list allowed dtypes, in which case we should skip this.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m allowed_dtypes:\n\u001b[0;32m--> 251\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m   \u001b[38;5;66;03m# If we did not match an allowed dtype, try again with the default\u001b[39;00m\n\u001b[1;32m    253\u001b[0m   \u001b[38;5;66;03m# dtype. This could be because we have an empty tensor and thus we\u001b[39;00m\n\u001b[1;32m    254\u001b[0m   \u001b[38;5;66;03m# picked the wrong type.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_dtypes:\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:209\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    207\u001b[0m overload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__tf_tensor__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moverload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[1;32m    213\u001b[0m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/CVAE/lib/python3.9/site-packages/keras/src/backend/common/keras_tensor.py:156\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.ops`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "if train_cvae:\n",
    "    \n",
    "    latent_dim = 16\n",
    "    batch_size = 16\n",
    "    beta = 1\n",
    "    gamma = 100\n",
    "    disentangle = True\n",
    "    cvae, z_encoder, s_encoder, cvae_decoder = get_MRI_CVAE_3D(latent_dim=latent_dim,beta=beta, disentangle=disentangle, gamma=gamma, bias=True, batch_size = batch_size)\n",
    "    loss = list()    \n",
    "    \n",
    "    fdir = 'tf_outputs/CVAE/'\n",
    "    fn = 'CVAE_weights'\n",
    "    \n",
    "    fn = os.path.join(fdir,fn)\n",
    "    loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape            </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to            </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv3d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv3d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │ conv3d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">524288</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">67,108,992</span> │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                             │                         │                │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv3d_14 (\u001b[38;5;33mConv3D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m1,792\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv3d_15 (\u001b[38;5;33mConv3D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m221,312\u001b[0m │ conv3d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m524288\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ conv3d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │     \u001b[38;5;34m67,108,992\u001b[0m │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z_mean (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │          \u001b[38;5;34m4,128\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z_log_var (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │          \u001b[38;5;34m4,128\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├─────────────────────────────┼─────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ z (\u001b[38;5;33mLambda\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                             │                         │                │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└─────────────────────────────┴─────────────────────────┴────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,340,352</span> (256.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,340,352\u001b[0m (256.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,340,352</span> (256.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,340,352\u001b[0m (256.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_decoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_batch = DX_subs[np.random.randint(low=0,high=DX_subs.shape[0],size=batch_size),:,:,:];\n",
    "TD_batch = TD_subs[np.random.randint(low=0,high=TD_subs.shape[0],size=batch_size),:,:,:];\n",
    "\n",
    "if len(loss)==0:\n",
    "    loss.append(np.nan)\n",
    "    im,im1,ss = cvae_query(BRAIN_data,s_encoder,z_encoder,cvae_decoder);\n",
    "    plot_trainProgress(loss,im,im1);\n",
    "    loss = list()\n",
    "else:\n",
    "    im,im1,ss = cvae_query(BRAIN_data,s_encoder,z_encoder,cvae_decoder);\n",
    "    plot_trainProgress(loss,im,im1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatches = 5000\n",
    "if train_cvae:\n",
    "    for i in tqdm(range(1,nbatches)):\n",
    "        \n",
    "        DX_batch = DX_subs[np.random.randint(low=0,high=DX_subs.shape[0],size=batch_size),:,:,:];\n",
    "        TD_batch = TD_subs[np.random.randint(low=0,high=TD_subs.shape[0],size=batch_size),:,:,:];\n",
    "        \n",
    "        hist = cvae.train_on_batch([DX_batch,TD_batch]);\n",
    "        loss.append(hist);\n",
    "        \n",
    "        mse = ((np.array([DX_batch,TD_batch])-np.array(cvae.predict([DX_batch,TD_batch]))[:,:,:,:,:,0])**2).mean()\n",
    "\n",
    "        assert not np.isnan(hist),'loss is NaN - somethings wrong'\n",
    "\n",
    "        im,im1,ss = cvae_query(BRAIN_data, s_encoder, z_encoder, cvae_decoder); \n",
    "\n",
    "        \n",
    "\n",
    "        if np.mod(i,5)==0: # Plot training progress\n",
    "            plot_trainProgress(loss,im,im1);\n",
    "            pickle.dump(loss,open(fn+'_loss.pickle','wb'))\n",
    "            plot_four(DX_batch, TD_batch, z_encoder, s_encoder,cvae_decoder,cvae,idx=0)\n",
    "            plot_four(DX_batch, TD_batch, z_encoder, s_encoder,cvae_decoder,cvae,idx=1)\n",
    "\n",
    "        if np.mod(i,10)==0: # Save every 10 batches\n",
    "            cvae.save_weights(fn)\n",
    "            \n",
    "        if mse < .0005:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "path = os.path.expanduser('~/Documents/Bilingualism_CVAE/data/tf_outputs/CVAE/CVAE_weights_loss.pickle')\n",
    "with open(path, 'rb') as handle:\n",
    "    loaded_object = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaded_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1000,len(loaded_object)), loaded_object[1000:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !module list\n",
    "# !nvidia-smi\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# from datetime import datetime;now = datetime.now;t00 = now()\n",
    "# print(t00)\n",
    "# # GPU checks\n",
    "# import tensorflow as tf\n",
    "# # tf.test.gpu_device_name()\n",
    "# # tf.test.is_gpu_available()\n",
    "# tf.test.gpu_device_name()\n",
    "# import timeit,pickle\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   print(\n",
    "#       '\\n\\nThis error most likely means that this notebook is not '\n",
    "#       'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "#       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "#   raise SystemError('GPU device not found')\n",
    "\n",
    "# def cpu():\n",
    "#   with tf.device('/cpu:0'):\n",
    "#     random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "#     net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "#     return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "# def gpu():\n",
    "#   with tf.device('/device:GPU:0'):\n",
    "#     random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "#     net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "#     return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# # We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "# cpu()\n",
    "# gpu()\n",
    "\n",
    "# # Run the op several times.\n",
    "# print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "#       '(batch x height x width x channel). Sum of ten runs.')\n",
    "# print('CPU (s):')\n",
    "# cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "# print(cpu_time)\n",
    "# print('GPU (s):')\n",
    "# gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "# print(gpu_time)\n",
    "# print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
